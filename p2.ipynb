{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "496b2dd2-a639-4d53-8dce-bf1cf01096c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ca22b3b-76a1-47bd-b3f9-caed9bce1814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_csv = pd.read_csv(\"test.csv\")\n",
    "train_csv = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f70339c-8fcd-4826-a403-01a67bfe32ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "nump_test = test_csv.values\n",
    "nump_train = train_csv.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13602add-55e6-4135-8f2e-6732c08d0a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_torch = torch.from_numpy(nump_test)\n",
    "train_torch = torch.from_numpy(nump_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b808e52d-31fb-4bb4-8e7e-61a8b05da231",
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = test_torch[:, :-1]\n",
    "testY = test_torch[:, -1]\n",
    "testY = testY.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ba8b3dd-851d-49b0-8ddc-492f5d629405",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = train_torch[:, :-1]\n",
    "trainY = train_torch[:, -1]\n",
    "trainY = trainY.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fad94e6c-e82c-4192-9353-50a64f66873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = testX.to(torch.float64)\n",
    "testY = testY.to(torch.float64)\n",
    "trainX = trainX.to(torch.float64)\n",
    "trainY = trainY.to(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4626b396-dd74-4284-bcc7-906b0fe4b85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype is: torch.float64\n",
      "shape is: torch.Size([1044, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "83520"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q1: about how many bytes does trainX consume?\n",
    "dtype = trainX.dtype\n",
    "print(\"dtype is:\", dtype) # float64 is 64 bits = 8 bytes\n",
    "shape = trainX.shape\n",
    "print(\"shape is:\", shape)\n",
    "consumption_trainX = 1044 * 10 * 8\n",
    "consumption_trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b8d8be8-b23a-4f47-bf82-15466c57fb01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q2: what is the biggest difference we would have any one cell if we used float16 instead of float64?\n",
    "trainx_64 = trainX\n",
    "trainx_16 = trainX.to(torch.float16)\n",
    "new_train = torch.sub(trainx_64, trainx_16)\n",
    "max_train = new_train.max()\n",
    "answer_q2 = max_train.item()\n",
    "answer_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb82bdb4-80b9-41f2-ac67-fa2b7cf26466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q3: is a CUDA GPU available on your VM?\n",
    "#help from: https://saturncloud.io/blog/how-to-check-whether-your-code-is-running-on-the-gpu-or-cpu/#:~:text=If%20you%27re%20using%20Python,is%20available%20and%20False%20otherwise\n",
    "answer_q3 = False\n",
    "if torch.cuda.is_available():\n",
    "    answer_q3 = True\n",
    "else:\n",
    "    answer_q3 = False\n",
    "answer_q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d21ab9ce-d846-45d3-b1c8-725fa81e04ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0040],\n",
       "        [0.0040],\n",
       "        [0.0040],\n",
       "        [0.0040],\n",
       "        [0.0040],\n",
       "        [0.0040],\n",
       "        [0.0300],\n",
       "        [0.0300],\n",
       "        [0.0300],\n",
       "        [0.0300]], dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = torch.tensor([\n",
    "        [0.0040],\n",
    "        [0.0040],\n",
    "        [0.0040],\n",
    "        [0.0040],\n",
    "        [0.0040],\n",
    "        [0.0040], # POS_50_59_CP\n",
    "        [0.0300], # POS_60_69_CP\n",
    "        [0.0300],\n",
    "        [0.0300],\n",
    "        [0.0300]\n",
    "], dtype=trainX.dtype)\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da825452-fde1-4130-a9d2-530cce52733e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.844"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q4: what is the predicted number of deaths for the first census tract?\n",
    "result = testX[0] * coef.view(-1)\n",
    "predicted_deaths = result.sum()\n",
    "predicted_deaths = predicted_deaths.item()\n",
    "predicted_deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40ca5653-e6fb-497c-a678-8982cfe21d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.073632183908048"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q5: what is the average number of predicted deaths, over the whole testX dataset?\n",
    "deaths = torch.matmul(testX, coef)    \n",
    "avg_deaths = torch.mean(deaths).item()\n",
    "avg_deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6f40042-5d50-43ae-85de-634bd1cba74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q6: first, what is y when x is a tensor containing 0.0?\n",
    "\n",
    "def f(x):\n",
    "    \n",
    "    return (x**2) - (8*x) + 19\n",
    "    \n",
    "x = torch.tensor(0.0)\n",
    "y = f(x)\n",
    "float(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ae8b067-8c6c-436d-85c0-9a9c46ad998a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.999999761581421"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q7: what x value minimizes y?\n",
    "\n",
    "x = torch.tensor(0.0, requires_grad=True)\n",
    "optimizer = torch.optim.SGD([x], lr=0.2)\n",
    "\n",
    "for epoch in range(100):\n",
    "    y = f(x)\n",
    "    y.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad() \n",
    "x.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea3ab334-22a3-4b6e-b7d1-c4342f80ed85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197.8007662835249"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q8: what is the MSE (mean-square error) when we make predictions using this vector of zero coefficients?\n",
    "#help from: chat6 pdf\n",
    "num_samples, num_features = trainX.shape\n",
    "\n",
    "coef_q8 = torch.zeros((num_features, 1), dtype=torch.float64)\n",
    "\n",
    "predictions_q8 = trainX @ coef_q8\n",
    "\n",
    "mse_q8 = torch.mean((predictions_q8 - trainY.view(-1, 1))**2).item()\n",
    "mse_q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0686674a-4c71-4c24-9b5f-7621fc9cb399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.8113940147193"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q9: what is the MSE over the training data, using the coefficients resulting from the above training?\n",
    "#help from: chat7 pdf\n",
    "torch.manual_seed(544)\n",
    "ds = torch.utils.data.TensorDataset(trainX, trainY)\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=50, shuffle=True)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "coef_q9 = torch.zeros((trainX.shape[1], 1), dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "\n",
    "optimizer_q9 = torch.optim.SGD([coef_q9], lr=0.000002)\n",
    "\n",
    "for epoch in range(500):\n",
    "    for batchX, batchY in dl:\n",
    "        predictions_q9 = batchX @ coef_q9\n",
    "        loss_q9 = loss_fn(predictions_q9, batchY.view(-1, 1))\n",
    "        \n",
    "        optimizer_q9.zero_grad()\n",
    "        loss_q9.backward()\n",
    "        optimizer_q9.step()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions_q9 = trainX @ coef_q9\n",
    "    mse_q9 = loss_fn(predictions_q9, trainY.view(-1, 1)).item()\n",
    "\n",
    "mse_q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26a1d346-c2af-4b6c-91ff-4a6fe6523aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.05854692548551"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q10: what is the MSE over the test data?\n",
    "#help from: chat7 pdf\n",
    "torch.manual_seed(544)\n",
    "ds = torch.utils.data.TensorDataset(trainX, trainY)\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=50, shuffle=True)\n",
    "loss_fn_q10 = torch.nn.MSELoss()\n",
    "coef_q10 = torch.zeros((testX.shape[1], 1), dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "optimizer_q10 = torch.optim.SGD([coef_q10], lr=0.000002)\n",
    "\n",
    "for epoch in range(500):\n",
    "    for batchX, batchY in dl:\n",
    "        predictions_q10 = batchX @ coef_q10\n",
    "        loss_q10 = loss_fn_q10(predictions_q10, batchY.view(-1, 1))\n",
    "        \n",
    "        optimizer_q10.zero_grad()\n",
    "        loss_q10.backward()\n",
    "        optimizer_q10.step()\n",
    "        \n",
    "with torch.no_grad():\n",
    "    predictions_q10 = testX @ coef_q10\n",
    "    mse_q10 = loss_fn_q10(predictions_q10, testY.view(-1, 1)).item()\n",
    "\n",
    "mse_q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468f6a77-1da8-4d3f-b990-7f4536a9446a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
